{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sowmya-2348562/NLP/blob/main/Sowmya_C_562_Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDCVCfWW9I_m",
        "outputId": "fdb9ba1e-ab33-4b88-a486-6d13005aae31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph=\"The realm of artificial intelligence (AI) is an endlessly captivating and rapidly evolving domain! ðŸŒŸ The potential for AI to revolutionize a multitude of industries is truly extraordinary. From processing massive datasets to formulating innovative solutions, the impact of AI is far-reaching and game-changing. My fascination with this field stems from its dynamic nature and its ability to reshape various sectors. However, it's crucial to acknowledge that AI development is not without its challenges. We mustn't underestimate the intricacies involved or overlook the ethical implications. It's imperative to approach AI with both enthusiasm and caution. ðŸ¤–ðŸ’¡ Embracing these complexities allows us to unlock new opportunities and drive progress in a responsible and ethical manner, ensuring a positive impact on society and technology.\""
      ],
      "metadata": {
        "id": "P2pU6Llkb_Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Tokenization"
      ],
      "metadata": {
        "id": "aUJlVRnofHOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "# Tokenize the paragraph into words\n",
        "word_tokens = word_tokenize(paragraph)\n",
        "\n",
        "# Print the word tokens\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIQ_RHT9Cw_C",
        "outputId": "a1dbad98-01e7-4af3-801a-2ee73db85997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'realm', 'of', 'artificial', 'intelligence', '(', 'AI', ')', 'is', 'an', 'endlessly', 'captivating', 'and', 'rapidly', 'evolving', 'domain', '!', 'ðŸŒŸ', 'The', 'potential', 'for', 'AI', 'to', 'revolutionize', 'a', 'multitude', 'of', 'industries', 'is', 'truly', 'extraordinary', '.', 'From', 'processing', 'massive', 'datasets', 'to', 'formulating', 'innovative', 'solutions', ',', 'the', 'impact', 'of', 'AI', 'is', 'far-reaching', 'and', 'game-changing', '.', 'My', 'fascination', 'with', 'this', 'field', 'stems', 'from', 'its', 'dynamic', 'nature', 'and', 'its', 'ability', 'to', 'reshape', 'various', 'sectors', '.', 'However', ',', 'it', \"'s\", 'crucial', 'to', 'acknowledge', 'that', 'AI', 'development', 'is', 'not', 'without', 'its', 'challenges', '.', 'We', 'must', \"n't\", 'underestimate', 'the', 'intricacies', 'involved', 'or', 'overlook', 'the', 'ethical', 'implications', '.', 'It', \"'s\", 'imperative', 'to', 'approach', 'AI', 'with', 'both', 'enthusiasm', 'and', 'caution', '.', 'ðŸ¤–ðŸ’¡', 'Embracing', 'these', 'complexities', 'allows', 'us', 'to', 'unlock', 'new', 'opportunities', 'and', 'drive', 'progress', 'in', 'a', 'responsible', 'and', 'ethical', 'manner', ',', 'ensuring', 'a', 'positive', 'impact', 'on', 'society', 'and', 'technology', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights: Word tokenization splits text into individual words, enabling analysis at the word level. It's a fundamental preprocessing step in natural language processing tasks.\n",
        "Possible Applications: Text classification, sentiment analysis, named entity recognition, topic modeling, machine translation, and more."
      ],
      "metadata": {
        "id": "x68Qj_TieMSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Tokenization"
      ],
      "metadata": {
        "id": "NLjbpvLYfMLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sent_tokens = sent_tokenize(paragraph)\n",
        "print(\"Sentence Tokenization:\", sent_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMGLVd6fD3Fi",
        "outputId": "05deef66-34de-4add-9bd6-b31b708d5432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Tokenization: ['The realm of artificial intelligence (AI) is an endlessly captivating and rapidly evolving domain!', 'ðŸŒŸ The potential for AI to revolutionize a multitude of industries is truly extraordinary.', 'From processing massive datasets to formulating innovative solutions, the impact of AI is far-reaching and game-changing.', 'My fascination with this field stems from its dynamic nature and its ability to reshape various sectors.', \"However, it's crucial to acknowledge that AI development is not without its challenges.\", \"We mustn't underestimate the intricacies involved or overlook the ethical implications.\", \"It's imperative to approach AI with both enthusiasm and caution.\", 'ðŸ¤–ðŸ’¡ Embracing these complexities allows us to unlock new opportunities and drive progress in a responsible and ethical manner, ensuring a positive impact on society and technology.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights: Sentence tokenization breaks text into individual sentences, facilitating analysis at the sentence level. It's crucial for tasks requiring sentence-level understanding.\n",
        "Possible Applications: Text summarization, machine translation, text segmentation, document categorization, and dialogue systems."
      ],
      "metadata": {
        "id": "VbSv1xXleRej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Punctuation-based Tokenizer"
      ],
      "metadata": {
        "id": "Tf9se_FbfPGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "punct_tokenizer = WordPunctTokenizer()\n",
        "punct_tokens = punct_tokenizer.tokenize(paragraph)\n",
        "print(\"Punctuation-based Tokenizer:\", punct_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dykl0b_DD4Ik",
        "outputId": "23576178-58c3-470f-fa7c-5ac1eeea03ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Punctuation-based Tokenizer: ['The', 'realm', 'of', 'artificial', 'intelligence', '(', 'AI', ')', 'is', 'an', 'endlessly', 'captivating', 'and', 'rapidly', 'evolving', 'domain', '!', 'ðŸŒŸ', 'The', 'potential', 'for', 'AI', 'to', 'revolutionize', 'a', 'multitude', 'of', 'industries', 'is', 'truly', 'extraordinary', '.', 'From', 'processing', 'massive', 'datasets', 'to', 'formulating', 'innovative', 'solutions', ',', 'the', 'impact', 'of', 'AI', 'is', 'far', '-', 'reaching', 'and', 'game', '-', 'changing', '.', 'My', 'fascination', 'with', 'this', 'field', 'stems', 'from', 'its', 'dynamic', 'nature', 'and', 'its', 'ability', 'to', 'reshape', 'various', 'sectors', '.', 'However', ',', 'it', \"'\", 's', 'crucial', 'to', 'acknowledge', 'that', 'AI', 'development', 'is', 'not', 'without', 'its', 'challenges', '.', 'We', 'mustn', \"'\", 't', 'underestimate', 'the', 'intricacies', 'involved', 'or', 'overlook', 'the', 'ethical', 'implications', '.', 'It', \"'\", 's', 'imperative', 'to', 'approach', 'AI', 'with', 'both', 'enthusiasm', 'and', 'caution', '.', 'ðŸ¤–ðŸ’¡', 'Embracing', 'these', 'complexities', 'allows', 'us', 'to', 'unlock', 'new', 'opportunities', 'and', 'drive', 'progress', 'in', 'a', 'responsible', 'and', 'ethical', 'manner', ',', 'ensuring', 'a', 'positive', 'impact', 'on', 'society', 'and', 'technology', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights: Punctuation-based tokenization splits text based on punctuation marks, separating words and punctuation symbols.\n",
        "Possible Applications: Preprocessing text for sentiment analysis, text classification, and information retrieval where punctuation usage is significant."
      ],
      "metadata": {
        "id": "2DBRZpWfeUui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treebank Word tokenizer"
      ],
      "metadata": {
        "id": "Lz4dLV1XfSKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "treebank_tokenizer = TreebankWordTokenizer()\n",
        "treebank_tokens = treebank_tokenizer.tokenize(paragraph)\n",
        "print(\"Treebank Word tokenizer:\", treebank_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vof7eYJD806",
        "outputId": "b4c1543c-2bcc-40c2-af36-c19099e3c1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treebank Word tokenizer: ['The', 'realm', 'of', 'artificial', 'intelligence', '(', 'AI', ')', 'is', 'an', 'endlessly', 'captivating', 'and', 'rapidly', 'evolving', 'domain', '!', 'ðŸŒŸ', 'The', 'potential', 'for', 'AI', 'to', 'revolutionize', 'a', 'multitude', 'of', 'industries', 'is', 'truly', 'extraordinary.', 'From', 'processing', 'massive', 'datasets', 'to', 'formulating', 'innovative', 'solutions', ',', 'the', 'impact', 'of', 'AI', 'is', 'far-reaching', 'and', 'game-changing.', 'My', 'fascination', 'with', 'this', 'field', 'stems', 'from', 'its', 'dynamic', 'nature', 'and', 'its', 'ability', 'to', 'reshape', 'various', 'sectors.', 'However', ',', 'it', \"'s\", 'crucial', 'to', 'acknowledge', 'that', 'AI', 'development', 'is', 'not', 'without', 'its', 'challenges.', 'We', 'must', \"n't\", 'underestimate', 'the', 'intricacies', 'involved', 'or', 'overlook', 'the', 'ethical', 'implications.', 'It', \"'s\", 'imperative', 'to', 'approach', 'AI', 'with', 'both', 'enthusiasm', 'and', 'caution.', 'ðŸ¤–ðŸ’¡', 'Embracing', 'these', 'complexities', 'allows', 'us', 'to', 'unlock', 'new', 'opportunities', 'and', 'drive', 'progress', 'in', 'a', 'responsible', 'and', 'ethical', 'manner', ',', 'ensuring', 'a', 'positive', 'impact', 'on', 'society', 'and', 'technology', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights: The Treebank tokenizer is based on the Penn Treebank corpus and handles complex linguistic structures like contractions and hyphenated words.\n",
        "Possible Applications: Part-of-speech tagging, parsing, named entity recognition, and syntactic analysis in NLP tasks."
      ],
      "metadata": {
        "id": "MAsxNwdJeaR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tweet Tokenizer  "
      ],
      "metadata": {
        "id": "dxVWkNPMfVY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "tweet_tokens = tweet_tokenizer.tokenize(paragraph)\n",
        "print(\"Tweet Tokenizer:\", tweet_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7SvNuumD_jO",
        "outputId": "12da465c-74c2-40bb-f355-a7e12218acf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet Tokenizer: ['The', 'realm', 'of', 'artificial', 'intelligence', '(', 'AI', ')', 'is', 'an', 'endlessly', 'captivating', 'and', 'rapidly', 'evolving', 'domain', '!', 'ðŸŒŸ', 'The', 'potential', 'for', 'AI', 'to', 'revolutionize', 'a', 'multitude', 'of', 'industries', 'is', 'truly', 'extraordinary', '.', 'From', 'processing', 'massive', 'datasets', 'to', 'formulating', 'innovative', 'solutions', ',', 'the', 'impact', 'of', 'AI', 'is', 'far-reaching', 'and', 'game-changing', '.', 'My', 'fascination', 'with', 'this', 'field', 'stems', 'from', 'its', 'dynamic', 'nature', 'and', 'its', 'ability', 'to', 'reshape', 'various', 'sectors', '.', 'However', ',', \"it's\", 'crucial', 'to', 'acknowledge', 'that', 'AI', 'development', 'is', 'not', 'without', 'its', 'challenges', '.', 'We', \"mustn't\", 'underestimate', 'the', 'intricacies', 'involved', 'or', 'overlook', 'the', 'ethical', 'implications', '.', \"It's\", 'imperative', 'to', 'approach', 'AI', 'with', 'both', 'enthusiasm', 'and', 'caution', '.', 'ðŸ¤–', 'ðŸ’¡', 'Embracing', 'these', 'complexities', 'allows', 'us', 'to', 'unlock', 'new', 'opportunities', 'and', 'drive', 'progress', 'in', 'a', 'responsible', 'and', 'ethical', 'manner', ',', 'ensuring', 'a', 'positive', 'impact', 'on', 'society', 'and', 'technology', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tweet_text = \"@sowmya_2348562 This is a #username with mentions, #mscaiml, and URLs https://christ.com \"\n",
        "\n",
        "tokenizer = TweetTokenizer()\n",
        "tokens = tokenizer.tokenize(tweet_text)\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytXwaPtBScED",
        "outputId": "59b1604f-9b41-431e-d31a-1553bf97e1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['@sowmya_2348562', 'This', 'is', 'a', '#username', 'with', 'mentions', ',', '#mscaiml', ',', 'and', 'URLs', 'https://christ.com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights: Tweet tokenization is specialized for handling text from social media platforms like Twitter, including hashtags, mentions, and emojis.\n",
        "Possible Applications: Sentiment analysis, social media monitoring, trend detection, and analyzing user engagement on social media platforms."
      ],
      "metadata": {
        "id": "C-sCnYUvefSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Word Expression Tokenizer"
      ],
      "metadata": {
        "id": "nsZL8rQSfY7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import MWETokenizer\n",
        "\n",
        "tokenizer = MWETokenizer([('artificial', 'intelligence'), ('natural', 'language', 'processing')])  # Define the multi-word expressions\n",
        "\n",
        "tokenized_paragraph = tokenizer.tokenize(paragraph.split())\n",
        "print(\"\\nMulti-Word Expression Tokenizer:\")\n",
        "\n",
        "print(tokenized_paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywm9WD9iMnf5",
        "outputId": "ed45fbfd-0181-489b-c9e2-05a5e42c62c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Multi-Word Expression Tokenizer:\n",
            "['The', 'realm', 'of', 'artificial_intelligence', '(AI)', 'is', 'an', 'endlessly', 'captivating', 'and', 'rapidly', 'evolving', 'domain!', 'ðŸŒŸ', 'The', 'potential', 'for', 'AI', 'to', 'revolutionize', 'a', 'multitude', 'of', 'industries', 'is', 'truly', 'extraordinary.', 'From', 'processing', 'massive', 'datasets', 'to', 'formulating', 'innovative', 'solutions,', 'the', 'impact', 'of', 'AI', 'is', 'far-reaching', 'and', 'game-changing.', 'My', 'fascination', 'with', 'this', 'field', 'stems', 'from', 'its', 'dynamic', 'nature', 'and', 'its', 'ability', 'to', 'reshape', 'various', 'sectors.', 'However,', \"it's\", 'crucial', 'to', 'acknowledge', 'that', 'AI', 'development', 'is', 'not', 'without', 'its', 'challenges.', 'We', \"mustn't\", 'underestimate', 'the', 'intricacies', 'involved', 'or', 'overlook', 'the', 'ethical', 'implications.', \"It's\", 'imperative', 'to', 'approach', 'AI', 'with', 'both', 'enthusiasm', 'and', 'caution.', 'ðŸ¤–ðŸ’¡', 'Embracing', 'these', 'complexities', 'allows', 'us', 'to', 'unlock', 'new', 'opportunities', 'and', 'drive', 'progress', 'in', 'a', 'responsible', 'and', 'ethical', 'manner,', 'ensuring', 'a', 'positive', 'impact', 'on', 'society', 'and', 'technology.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights: Multi-word expression tokenizer identifies and tokenizes phrases composed of multiple words that function as a single semantic unit.\n",
        "Possible Applications: Named entity recognition, information extraction, machine translation, and sentiment analysis where multi-word expressions are crucial."
      ],
      "metadata": {
        "id": "9pjyEpkjeg4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TextBlob Word Tokenize"
      ],
      "metadata": {
        "id": "v2G_K3yxfb4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text_blob = TextBlob(paragraph)\n",
        "textblob_tokens = text_blob.words\n",
        "print(\"TextBlob Word Tokenize:\", textblob_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrejY-XpMM3c",
        "outputId": "e35662ca-cb9a-46df-8bec-ef6f4ba60302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TextBlob Word Tokenize: ['The', 'realm', 'of', 'artificial', 'intelligence', 'AI', 'is', 'an', 'endlessly', 'captivating', 'and', 'rapidly', 'evolving', 'domain', 'ðŸŒŸ', 'The', 'potential', 'for', 'AI', 'to', 'revolutionize', 'a', 'multitude', 'of', 'industries', 'is', 'truly', 'extraordinary', 'From', 'processing', 'massive', 'datasets', 'to', 'formulating', 'innovative', 'solutions', 'the', 'impact', 'of', 'AI', 'is', 'far-reaching', 'and', 'game-changing', 'My', 'fascination', 'with', 'this', 'field', 'stems', 'from', 'its', 'dynamic', 'nature', 'and', 'its', 'ability', 'to', 'reshape', 'various', 'sectors', 'However', 'it', \"'s\", 'crucial', 'to', 'acknowledge', 'that', 'AI', 'development', 'is', 'not', 'without', 'its', 'challenges', 'We', 'must', \"n't\", 'underestimate', 'the', 'intricacies', 'involved', 'or', 'overlook', 'the', 'ethical', 'implications', 'It', \"'s\", 'imperative', 'to', 'approach', 'AI', 'with', 'both', 'enthusiasm', 'and', 'caution', 'ðŸ¤–ðŸ’¡', 'Embracing', 'these', 'complexities', 'allows', 'us', 'to', 'unlock', 'new', 'opportunities', 'and', 'drive', 'progress', 'in', 'a', 'responsible', 'and', 'ethical', 'manner', 'ensuring', 'a', 'positive', 'impact', 'on', 'society', 'and', 'technology']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights: TextBlob's word tokenize function provides a simple interface for word tokenization, suitable for basic text processing tasks.\n",
        "Possible Applications: Basic text analysis, sentiment analysis, text classification, and part-of-speech tagging in applications requiring quick and easy text processing."
      ],
      "metadata": {
        "id": "81HzlFyvekIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "spaCy Tokenizer"
      ],
      "metadata": {
        "id": "Qn8eBY5Ofem_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(paragraph)\n",
        "spacy_tokens = [token.text for token in doc]\n",
        "print(\"spaCy Tokenizer:\", spacy_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM0i7kaoNHl3",
        "outputId": "a5001402-595f-4bb8-e9b9-8aaf098ae2d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy Tokenizer: ['The', 'realm', 'of', 'artificial', 'intelligence', '(', 'AI', ')', 'is', 'an', 'endlessly', 'captivating', 'and', 'rapidly', 'evolving', 'domain', '!', 'ðŸŒŸ', 'The', 'potential', 'for', 'AI', 'to', 'revolutionize', 'a', 'multitude', 'of', 'industries', 'is', 'truly', 'extraordinary', '.', 'From', 'processing', 'massive', 'datasets', 'to', 'formulating', 'innovative', 'solutions', ',', 'the', 'impact', 'of', 'AI', 'is', 'far', '-', 'reaching', 'and', 'game', '-', 'changing', '.', 'My', 'fascination', 'with', 'this', 'field', 'stems', 'from', 'its', 'dynamic', 'nature', 'and', 'its', 'ability', 'to', 'reshape', 'various', 'sectors', '.', 'However', ',', 'it', \"'s\", 'crucial', 'to', 'acknowledge', 'that', 'AI', 'development', 'is', 'not', 'without', 'its', 'challenges', '.', 'We', 'must', \"n't\", 'underestimate', 'the', 'intricacies', 'involved', 'or', 'overlook', 'the', 'ethical', 'implications', '.', 'It', \"'s\", 'imperative', 'to', 'approach', 'AI', 'with', 'both', 'enthusiasm', 'and', 'caution', '.', 'ðŸ¤–', 'ðŸ’¡', 'Embracing', 'these', 'complexities', 'allows', 'us', 'to', 'unlock', 'new', 'opportunities', 'and', 'drive', 'progress', 'in', 'a', 'responsible', 'and', 'ethical', 'manner', ',', 'ensuring', 'a', 'positive', 'impact', 'on', 'society', 'and', 'technology', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights: spaCy's tokenizer is highly efficient and capable of handling complex linguistic features, including named entities, compound words, and punctuation.\n",
        "Possible Applications: Named entity recognition, dependency parsing, text classification, and information extraction where accurate tokenization and linguistic annotations are critical."
      ],
      "metadata": {
        "id": "2huoHreBeob3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gensim word tokenizer"
      ],
      "metadata": {
        "id": "80AvogXAfh7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.utils import tokenize\n",
        "\n",
        "gensim_tokens = list(tokenize(paragraph))\n",
        "print(\"Gensim word tokenizer:\", gensim_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8xCX2hzOMjh",
        "outputId": "e4b0c91c-af08-40ff-f9c5-ad4c1d933560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gensim word tokenizer: ['The', 'realm', 'of', 'artificial', 'intelligence', 'AI', 'is', 'an', 'endlessly', 'captivating', 'and', 'rapidly', 'evolving', 'domain', 'The', 'potential', 'for', 'AI', 'to', 'revolutionize', 'a', 'multitude', 'of', 'industries', 'is', 'truly', 'extraordinary', 'From', 'processing', 'massive', 'datasets', 'to', 'formulating', 'innovative', 'solutions', 'the', 'impact', 'of', 'AI', 'is', 'far', 'reaching', 'and', 'game', 'changing', 'My', 'fascination', 'with', 'this', 'field', 'stems', 'from', 'its', 'dynamic', 'nature', 'and', 'its', 'ability', 'to', 'reshape', 'various', 'sectors', 'However', 'it', 's', 'crucial', 'to', 'acknowledge', 'that', 'AI', 'development', 'is', 'not', 'without', 'its', 'challenges', 'We', 'mustn', 't', 'underestimate', 'the', 'intricacies', 'involved', 'or', 'overlook', 'the', 'ethical', 'implications', 'It', 's', 'imperative', 'to', 'approach', 'AI', 'with', 'both', 'enthusiasm', 'and', 'caution', 'Embracing', 'these', 'complexities', 'allows', 'us', 'to', 'unlock', 'new', 'opportunities', 'and', 'drive', 'progress', 'in', 'a', 'responsible', 'and', 'ethical', 'manner', 'ensuring', 'a', 'positive', 'impact', 'on', 'society', 'and', 'technology']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights: Gensim's word tokenizer splits text into words based on whitespace and punctuation, suitable for basic text processing tasks.\n",
        "Possible Applications: Topic modeling, document similarity analysis, document clustering, and word embedding training in tasks involving large text corpora."
      ],
      "metadata": {
        "id": "rn61Esy-eq--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "gensim_tokens = paragraph.split()\n",
        "print(\"\\nGensim Word Tokenizer:\")\n",
        "print(gensim_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpo8yS47Ofky",
        "outputId": "d3943db0-df3c-431f-c97c-3d077df416d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gensim Word Tokenizer:\n",
            "['The', 'realm', 'of', 'artificial', 'intelligence', '(AI)', 'is', 'an', 'endlessly', 'captivating', 'and', 'rapidly', 'evolving', 'domain!', 'ðŸŒŸ', 'The', 'potential', 'for', 'AI', 'to', 'revolutionize', 'a', 'multitude', 'of', 'industries', 'is', 'truly', 'extraordinary.', 'From', 'processing', 'massive', 'datasets', 'to', 'formulating', 'innovative', 'solutions,', 'the', 'impact', 'of', 'AI', 'is', 'far-reaching', 'and', 'game-changing.', 'My', 'fascination', 'with', 'this', 'field', 'stems', 'from', 'its', 'dynamic', 'nature', 'and', 'its', 'ability', 'to', 'reshape', 'various', 'sectors.', 'However,', \"it's\", 'crucial', 'to', 'acknowledge', 'that', 'AI', 'development', 'is', 'not', 'without', 'its', 'challenges.', 'We', \"mustn't\", 'underestimate', 'the', 'intricacies', 'involved', 'or', 'overlook', 'the', 'ethical', 'implications.', \"It's\", 'imperative', 'to', 'approach', 'AI', 'with', 'both', 'enthusiasm', 'and', 'caution.', 'ðŸ¤–ðŸ’¡', 'Embracing', 'these', 'complexities', 'allows', 'us', 'to', 'unlock', 'new', 'opportunities', 'and', 'drive', 'progress', 'in', 'a', 'responsible', 'and', 'ethical', 'manner,', 'ensuring', 'a', 'positive', 'impact', 'on', 'society', 'and', 'technology.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization with Keras"
      ],
      "metadata": {
        "id": "z4TSai4Uflmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "keras_tokens = text_to_word_sequence(paragraph)\n",
        "print(\"Tokenization with Keras:\", keras_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-CLIrHoOj7e",
        "outputId": "bc0a7bc5-772f-489e-a5f9-d90e025a8d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization with Keras: ['the', 'realm', 'of', 'artificial', 'intelligence', 'ai', 'is', 'an', 'endlessly', 'captivating', 'and', 'rapidly', 'evolving', 'domain', 'ðŸŒŸ', 'the', 'potential', 'for', 'ai', 'to', 'revolutionize', 'a', 'multitude', 'of', 'industries', 'is', 'truly', 'extraordinary', 'from', 'processing', 'massive', 'datasets', 'to', 'formulating', 'innovative', 'solutions', 'the', 'impact', 'of', 'ai', 'is', 'far', 'reaching', 'and', 'game', 'changing', 'my', 'fascination', 'with', 'this', 'field', 'stems', 'from', 'its', 'dynamic', 'nature', 'and', 'its', 'ability', 'to', 'reshape', 'various', 'sectors', 'however', \"it's\", 'crucial', 'to', 'acknowledge', 'that', 'ai', 'development', 'is', 'not', 'without', 'its', 'challenges', 'we', \"mustn't\", 'underestimate', 'the', 'intricacies', 'involved', 'or', 'overlook', 'the', 'ethical', 'implications', \"it's\", 'imperative', 'to', 'approach', 'ai', 'with', 'both', 'enthusiasm', 'and', 'caution', 'ðŸ¤–ðŸ’¡', 'embracing', 'these', 'complexities', 'allows', 'us', 'to', 'unlock', 'new', 'opportunities', 'and', 'drive', 'progress', 'in', 'a', 'responsible', 'and', 'ethical', 'manner', 'ensuring', 'a', 'positive', 'impact', 'on', 'society', 'and', 'technology']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights: Tokenization with Keras converts text into sequences of tokens, preparing it for input into neural network models.\n",
        "\n",
        "Possible Applications: Text classification, sequence labeling, language modeling, and sentiment analysis using deep learning models."
      ],
      "metadata": {
        "id": "tWhU_5GJevcI"
      }
    }
  ]
}